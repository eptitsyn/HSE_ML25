"""Streamlit –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ü–µ–Ω –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π."""

from __future__ import annotations

import pickle
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import numpy as np
import pandas as pd
import streamlit as st

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
ROOT = Path(__file__).resolve().parent
ARTIFACTS_PATH = ROOT / "models" / "car_price_artifacts.pkl"
EPSILON = 1e-6

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥—É–ª–µ–π –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å pickle
sys.modules.setdefault("main", sys.modules[__name__])
sys.modules.setdefault("__main__", sys.modules[__name__])


@dataclass
class ModelMetadata:
    """–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."""

    feature_names: list[str]
    numeric_cols: list[str]
    cat_cols: list[str]
    categories: dict[str, list[Any]]
    medians: dict[str, float]


def split_name_column(df):
    """–†–∞–∑–±–∏–≤–∞–µ—Ç –∫–æ–ª–æ–Ω–∫—É name –Ω–∞ brand, model –∏ version."""
    df = df.copy()

    if "name" not in df.columns:
        return df

    parts = df["name"].astype(str).str.split()
    df["brand"] = parts.str[0].replace({"nan": np.nan})
    df["model"] = parts.str[1].replace({"nan": np.nan})
    df["version"] = parts.str[2:].apply(
        lambda x: " ".join(x) if isinstance(x, list) else ""
    )

    return df.drop(columns=["name"])


def add_brand_model_version(df):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ brand, model, version –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ name."""
    df = df.copy()

    if "name" not in df.columns:
        return df

    parts = df["name"].astype(str).str.split()
    df["brand"] = parts.str[0].replace({"nan": np.nan})
    df["model"] = parts.str[1].replace({"nan": np.nan})
    df["version"] = parts.apply(
        lambda x: " ".join(x[2:]) if isinstance(x, list) and len(x) > 2 else ""
    )

    # –ï—Å–ª–∏ name –±—ã–ª NaN, —Ç–æ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å NaN
    name_is_nan = df["name"].isna()
    df.loc[name_is_nan, ["brand", "model", "version"]] = np.nan

    return df


def add_handcrafted_features(df):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–∫–æ–Ω—Å—Ç—Ä—É–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏."""
    df = df.copy()

    if "engine" in df.columns:
        df["engine_liters"] = df["engine"] / 1000.0

    if "engine_liters" in df.columns and "max_power" in df.columns:
        safe_engine = df["engine_liters"].replace(0, np.nan) + EPSILON
        df["power_per_liter"] = df["max_power"] / safe_engine

    if "engine_liters" in df.columns and "torque_nm" in df.columns:
        safe_engine = df["engine_liters"].replace(0, np.nan) + EPSILON
        df["torque_per_liter"] = df["torque_nm"] / safe_engine

    if "year" in df.columns:
        ref_year = df["year"].max()
        df["car_age"] = (ref_year - df["year"]).clip(lower=0)

    if "car_age" in df.columns and "km_driven" in df.columns:
        safe_age = df["car_age"].replace(0, np.nan) + EPSILON
        df["km_per_year"] = df["km_driven"] / safe_age

    if "km_driven" in df.columns:
        df["log_km_driven"] = np.log1p(df["km_driven"])

    if "max_power" in df.columns:
        df["log_max_power"] = np.log1p(df["max_power"].clip(lower=0))

    return df


def align_with_features(df, feature_names):
    """–í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ DataFrame —Å –æ–∂–∏–¥–∞–µ–º—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏."""
    df = add_brand_model_version(df)

    for col in feature_names:
        if col not in df.columns:
            df[col] = np.nan

    return df[feature_names]


def is_int_like(value):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–Ω–æ –ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ."""
    try:
        return float(value).is_integer()
    except (TypeError, ValueError, AttributeError):
        return False


class ArtifactUnpickler(pickle.Unpickler):
    """Unpickler —Å –ø–æ–¥–º–µ–Ω–æ–π –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π."""

    def __init__(self, file, extra_funcs):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è unpickler."""
        super().__init__(file)
        self.extra_funcs = extra_funcs

    def find_class(self, module, name):
        """–ü–æ–∏—Å–∫ –∫–ª–∞—Å—Å–∞ –∏–ª–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ –∏–º–µ–Ω–∏."""
        if name in self.extra_funcs:
            return self.extra_funcs[name]
        return super().find_class(module, name)


@st.cache_resource(show_spinner=True)
def load_artifacts(path=ARTIFACTS_PATH):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç pipeline –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤."""
    if not path.exists():
        raise FileNotFoundError(f"–§–∞–π–ª –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")

    # –§—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –≤ pickle
    extra_funcs = {
        "split_name_column": split_name_column,
        "add_brand_model_version": add_brand_model_version,
        "add_handcrafted_features": add_handcrafted_features,
    }

    with open(path, "rb") as f:
        artifacts = ArtifactUnpickler(f, extra_funcs).load()

    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ pipeline –∏ —Å–ª–æ–≤–∞—Ä—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
    pipeline = None
    artifacts_dict = {}

    if hasattr(artifacts, "named_steps"):
        pipeline = artifacts
    elif isinstance(artifacts, dict):
        artifacts_dict = artifacts
        pipeline = artifacts_dict.get("pipeline")

        # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–π –≤ –º–æ–¥—É–ª–µ main
        for name, val in artifacts_dict.items():
            if callable(val):
                setattr(sys.modules["main"], name, val)

    # –í–∞–ª–∏–¥–∞—Ü–∏—è pipeline
    if pipeline is None:
        raise KeyError("Pipeline –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞—Ö")

    if not hasattr(pipeline, "named_steps") or "preprocess" not in pipeline.named_steps:
        raise TypeError("–û–∂–∏–¥–∞–µ—Ç—Å—è sklearn Pipeline —Å —à–∞–≥–æ–º preprocess")

    preprocess = pipeline.named_steps["preprocess"]
    if not hasattr(preprocess, "feature_names_in_"):
        raise AttributeError(
            "–£ preprocess –Ω–µ—Ç –∞—Ç—Ä–∏–±—É—Ç–∞ feature_names_in_. "
            "Pipeline –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ–±—É—á–µ–Ω –Ω–∞ DataFrame."
        )

    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    ohe = artifacts_dict.get("ohe")
    cat_cols = list(artifacts_dict.get("cat_cols", []))
    categories = {}

    if hasattr(ohe, "categories_"):
        categories = {
            col: list(opts) for col, opts in zip(cat_cols, ohe.categories_)
        }

    metadata = ModelMetadata(
        feature_names=list(preprocess.feature_names_in_),
        numeric_cols=list(artifacts_dict.get("numeric_cols", [])),
        cat_cols=cat_cols,
        categories=categories,
        medians=artifacts_dict.get("median_dict", {}),
    )

    return pipeline, metadata


def render_single_car_mode(pipeline, metadata):
    """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."""
    st.header("üßç –û–¥–∏–Ω–æ—á–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑")

    with st.form("single_car_form"):
        col1, col2 = st.columns(2)
        inputs = {}

        numeric_cols = set(metadata.numeric_cols)
        cat_cols = set(metadata.cat_cols)

        # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–∂–µ—Ç–æ–≤ –≤–≤–æ–¥–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
        for idx, col_name in enumerate(metadata.feature_names):
            target_col = col1 if idx % 2 == 0 else col2

            if col_name in cat_cols:
                # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫
                options = metadata.categories.get(col_name, [])
                if options:
                    inputs[col_name] = target_col.selectbox(f"{col_name}", options)
                else:
                    inputs[col_name] = target_col.text_input(f"{col_name}")

            elif col_name in numeric_cols:
                # –ß–∏—Å–ª–æ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫
                median = metadata.medians.get(col_name, 0.0)
                if median is None:
                    median = 0.0

                step = 1 if is_int_like(median) else 0.1
                default_val = int(median) if is_int_like(median) else float(median)

                inputs[col_name] = target_col.number_input(
                    f"{col_name}", value=default_val, step=step
                )
            else:
                # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø
                inputs[col_name] = target_col.text_input(f"{col_name}")

        submitted = st.form_submit_button("–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Ü–µ–Ω—É")

    if submitted:
        df_single = pd.DataFrame([inputs])

        st.subheader("–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        st.write(df_single)

        df_single = align_with_features(df_single, metadata.feature_names)

        try:
            y_pred = pipeline.predict(df_single)[0]
            st.success(f"–û—Ü–µ–Ω–æ—á–Ω–∞—è —Ü–µ–Ω–∞: **{y_pred:,.0f}**")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")


def render_batch_mode(pipeline, metadata):
    """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."""
    st.header("üìÅ –ü–∞–∫–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ CSV")

    st.markdown(
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏, —Å–æ–≤–ø–∞–¥–∞—é—â–∏–º–∏ —Å –æ–±—É—á–∞—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏.
        –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –±—É–¥—É—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∞–º–∏.

        **–ü—Ä–∏–º–µ—Ä—ã –∫–æ–ª–æ–Ω–æ–∫:** name, year, km_driven, fuel, seller_type,
        transmission, owner, mileage, engine, max_power, seats, torque_nm, torque_rpm
        """
    )

    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª", type=["csv"])

    if uploaded_file is not None:
        try:
            df_input = pd.read_csv(uploaded_file)
        except Exception as e:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV: {e}")
            return

        st.subheader("–ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        st.write(df_input.head())

        if st.button("–°–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"):
            df_for_model = align_with_features(df_input.copy(), metadata.feature_names)

            try:
                preds = pipeline.predict(df_for_model)
                df_result = df_input.copy()
                df_result["predicted_price"] = preds

                st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
                st.write(df_result.head())

                csv_bytes = df_result.to_csv(index=False).encode("utf-8")
                st.download_button(
                    label="–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CSV",
                    data=csv_bytes,
                    file_name="car_price_predictions.csv",
                    mime="text/csv",
                )
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    st.set_page_config(
        page_title="–ü—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã –∞–≤—Ç–æ", page_icon="üöó", layout="wide"
    )

    st.title("üöó –ü—Ä–æ–≥–Ω–æ–∑ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è")
    st.markdown(
        """
        –î–µ–º–æ-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ü–µ–Ω –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π.

        - –ú–æ–¥–µ–ª—å –∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —É–ø–∞–∫–æ–≤–∞–Ω—ã –≤ sklearn Pipeline
        - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –ø—Ä–∏–∑–Ω–∞–∫–∞–º –∏–∑ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ CSV
        """
    )

    # –ó–∞–≥—Ä—É–∑–∫–∞ pipeline –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    try:
        pipeline, metadata = load_artifacts(ARTIFACTS_PATH)
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã: {e}")
        st.stop()

    # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã
    mode = st.sidebar.radio(
        "–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:",
        ("–û–¥–∏–Ω–æ—á–Ω—ã–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å", "–ü–∞–∫–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (CSV)"),
    )

    # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    if mode == "–û–¥–∏–Ω–æ—á–Ω—ã–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å":
        render_single_car_mode(pipeline, metadata)
    elif mode == "–ü–∞–∫–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (CSV)":
        render_batch_mode(pipeline, metadata)


if __name__ == "__main__":
    main()
